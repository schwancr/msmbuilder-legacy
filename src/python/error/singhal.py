import IPython
import numpy as np
from msmbuilder.error import MSMError
from msmbuilder import msm_analysis
import scipy.sparse
import logging
logger = logging.getLogger(__name__)

ZERO_THRESHOLD = 1E-8

class SinghalError(MSMError):
    """
    This class uses the method developed by Nina Singhal Hinrichs
    described in:

    [1] Hinrichs, N. S. and Pande, V.S. Calculation of the distribution of 
        eigenvalues and eigenvectors in Markovian state models for molecular 
        dynamics. J. Chem. Phys. 2007, 126, 244101.

    Briefly, the methods will calculate standard deviations in the eigenvalues
    as well as the eigenvector entries for a given MSM.
    """

    def __init__(self, tProb, force_dense=False):
        """
        Initialize the object:
        
        Parameters
        ----------
        tProb : scipy.sparse matrix or np.ndarray
            transition probability matrix generated by MSMBuilder
            
        Notes
        -----
        If the transition probability matrix was generated with the sliding
            window, then the errors will be systematically too small. If 
            possible you should build a model without sliding window and 
            calculate error bars with this model.
        The variables used in the source code match the cited paper wherever
            possible.
        """

        self.tProb = tProb

        self.issparse = scipy.sparse.issparse(tProb)

        if force_dense:
            if self.issparse:
                self.issparse = False
                logger.warning("Forcing dense operations. Watch your memory...")
                self.tProb = self.tProb.toarray()

        if self.issparse:
            tProb.tocsr()
            logger.warning("Dense is the only thing that works :(")
            self.issparse = False
            self.tProb = self.tProb.asarray()
            
            # most scipy methods prefer csr

    def get_eigenvalue_variances(self, which_eigenvalues=None, counts=None):
        """
        Calculate the variances in the the eigenvalues of the MSM
        
        Parameters
        ----------
        which_eigenvalues : list or int, optional
            calculate the variance in one or more eigenvalues. If None, then
            calculate variances for all eigenvalues.
        
        Returns
        -------
        variances : np.ndarray
            the variance for each requested eigenvalue in the order requested
        """

        # First step is to calculate the derivatives with respect to each
        # entry in the transition probability matrix       
        # As derived in [1] (see class docstring) we can solve this by 
        # by calculating the LU-decomposition of A = P - lambda I, where P is
        # the transition matrix

        vals, vecs = msm_analysis.get_eigenvectors(self.tProb, 
            np.max(which_eigenvalues) + 1)

        num_states = self.tProb.shape[0]
        dLambda_dT = self.__get_eigenvalue_derivatives__(vals[which_eigenvalues])
        # dLambda_dT is a matrix corresponding to the derivative of the
        # eigenvalue with respect to all entries in self.tProb
        # this is the s^\lambda matrix.

        counts_per_state = counts.sum(axis=1)       
        running_sum = 0
        for i in xrange(self.tProb.shape[0]):
            middle_mat = np.eye(num_states) * self.tProb[i] - np.outer(self.tProb[i], self.tProb[i])

            qi = dLambda_dT[i].dot(middle_mat).dot(dLambda_dT[i])

            running_sum += qi / (counts_per_state[i] + 1)
            
        return running_sum 


    def __get_eigenvalue_derivatives__(self, eigenvalue):
        """
        Internal function for doing the calculating necessary for calculating
        errors using the Singhal method.
        
        You should use get_eigenvalue_variances
        """
    
        num_states = self.tProb.shape[0]

        # Abar is (T - \lambda I) where T is the transition matrix
        # L, U are the lower and upper diagoanl matrices such that Abar = LU
        if self.issparse:
            Abar = self.tProb - eigenvalue * scipy.sparse.eye(num_states, num_states)
            # not sure how to make this work yet... There may not be
            # a sparse implementation
            factorized_lu = scipy.sparse.linalg.splu(Abar)
            L, U = factorized_lu.solve()
        else:
            Abar = self.tProb - eigenvalue * np.eye(num_states)
            L_trans, U_trans = scipy.linalg.lu(Abar.T, permute_l=True)
            L = U_trans.T
            U = L_trans.T
            # scipy puts the unit diagonal in the L matrix, but Singhal specify
            # that U has unit diagonal entries

        # CRS: I am fairly confident I am doing this wrong...
        zero_diagonal_index = np.where(np.abs(L.diagonal()) <= ZERO_THRESHOLD)
        #print zero_diagonal_index, L.diagonal()
        zero_diagonal_index = zero_diagonal_index[0][0]
        # this corresponds to the K used in [1]
        # There needs to be a zero entry in L's diagonal because det(Abar) = 0

        # e_K is a column vector corresponding the K'th column of the identity
        # matrix
        e_K = np.zeros((num_states, 1))
        e_K[zero_diagonal_index] = 1.

        zero_col = np.zeros((num_states, 1))
        # x is the solution to the upper diagonal equation:
        # U x = e_K
        # x_a is the solution to the lower diagonal equation:
        # L^T x_a = 0
        # where 0 is a column vector of zeros

        if self.issparse:
            x = scipy.linalg.sparse.spsolve(U, e_K)
            x_a = scipy.linalg.sparse.spsolve(L.T, zero_col)
        else:
            x = scipy.linalg.solve(U, e_K)
            # equation 2 is the null spce of L^T, so we will solve this
            # with SVD:
            U, S, VH = scipy.linalg.svd(L.T) 
            zero_ind = np.where(S <= ZERO_THRESHOLD)
            x_a = VH[zero_ind].flatten()
        #    print zero_ind, zero_diagonal_index
            # pretty sure these should be the same...
            #x_a = scipy.linalg.solve(L.T, zero_col)
            # The above just returns the trivial solution, which isn't 
            # interesting

        #print x_a
        # there are many solutions to the second equation, so Singhal-
        # Hinrichs choose the solutions such that:
        # x_a[K] = 1
        x_a = x_a / x_a[zero_diagonal_index]

        # This may or may not be an array already, but it is not sparse so we 
        # make it an array
        if scipy.sparse.issparse(x_a):
            x_a = x_a.asarray()
        if scipy.sparse.issparse(x):
            x = x.asarray()

        print x_a.shape, x.shape
        dlambda_dT = np.outer(x_a, x) / np.dot(x_a, x)
        # dlambda_dT is the matrix of derivatives of the particular eigenvalue
        # with respect to the elements of the transition matrix

        return dlambda_dT
        
